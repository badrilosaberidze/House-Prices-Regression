### House Prices - Kaggle კონკურსის მონაცემებზე დაფუძნებული პროგნოზირების მოდელი

### Kaggle-ის კონკურსის მოკლე მიმოხილვა  
ამ კონკურსის მიზანია საცხოვრებელი სახლების ფასების პროგნოზირება სხვადასხვა ცვლადების გამოყენებით. მონაცემები მოიცავს სახლების სტრუქტურულ, მდებარეობით და სხვა მახასიათებლებს, რაც საჭიროა მოდელის ტრენინგისა და პროგნოზირებისთვის.

### ჩემი მიდგომა პრობლემის გადასაჭრელად  
პროექტის დასაწყისში გამოვიყენე ლინეარული რეგრესია, როგორც საბაზისო მოდელი, რათა გამერკვია პრობლემის სირთულე და შეფასებულიყო მინიმალური შედეგები. შემდეგ ეტაპებზე დავამატე რეგულარიზებული მოდელები (Ridge) და საბოლოოდ გადავედი უფრო კომპლექსურ მოდელზე — Random Forest-ზე. მთლიანად ავაშენე სპეციალური preprocessing pipeline: გაუმჯობესებული Feature Engineering, კორელაციის ანალიზი, encoding ტექნიკები და GridSearchCV ჰიპერპარამეტრების ოპტიმიზაციისთვის.

---

# რეპოზიტორიის სტრუქტურა  
### ყველა ფაილის განმარტება  
- `notebooks/` — Jupyter notebooks მოდელის კვლევისა და შედეგების ვიზუალიზაციისთვის  
- `preprocessing/` — ყველა custom preprocessing კლასი და მოდელის ტრეინინგის სკრიპტები 
- `README.md` — პროექტის აღწერა   

---

# Feature Engineering  
### კატეგორიული ცვლადების რიცხვითში გადაყვანა  
- მაღალი უნიკალური მნიშვნელობის მქონე კატეგორიული ცვლადებისთვის გამოყენებულია WOE (Weight of Evidence) კოდირება  
- დაბალი უნიკალურობის ცვლადებისთვის გამოყენებულია One-Hot Encoding
- მათ გამყოფ threshold ად აღებული მაქვს 3 შესაბამისად თუ უნიკალური ცვლადები < 3 ვიყენებთ One-Hot Encoding წინააღმდეგ შემთხვევაში WOE   

### Nan მნიშვნელობების დამუშავება  
- რიცხვითი ცვლადებისთვის გამოყენებულია საშუალო მნიშვნელობით შევსება  
- კატეგორიული ცვლადებისთვის გამოყენებულია ყველაზე ხშირად გამეორებადი მნიშვნელობა  

### Cleaning მიდგომები  
- აშკარად გამოუსადეგარი ან გამრუდებული ფიჩერების ამოღება  
- ძალზე კორელირებული ცვლადებიდან მხოლოდ ერთი რჩება, დანარჩენი იშლება  

---

# Feature Selection  
### გამოყენებული მიდგომები და მათი შეფასება  
- ფიჩერების შერჩევისთვის არ მომიხდენია ავტომატიზირებული მეთოდების გამოყენება როგორიცაა Pearson-ის კორელაციის ან Mutual Information-ის ანალიზი, არამედ ვამჯობინე უფრო ინტუიციური, ხელით დაფუძნებული მიდგომა:

- მძიმე კორელირებული ფიჩერების შერჩევა: ძალიან მაღალი კორელაციის მქონე ფიჩერებიდან შევარჩიე მხოლოდ ერთ-ერთი, რომელიც მეტად იყო კავშირში სამიზნე ცვლადთან (target variable) და დანარჩენები ამოვაგდე.

- დაბალი მნიშვნელობის ან/და ზედმეტი ინფორმაციის შემცველი ფიჩერების გამორიცხვა: მაგალითად, ისეთი კატეგორიული ფიჩერები, რომლებიც ბევრ უნიკალურ მნიშვნელობას შეიცავდნენ და ვერ აღწერდნენ კარგად სამიზნე ცვლადს, არ შევიტანე საბოლოო მოდელში.

- პრეპროცესინგის დროს ქასთომ ტრანსფორმერით შესრულებული ფილტრაცია: Feature Selection ნაწილობრივ შესრულდა ჩემს მიერ დაწერილ CustomPreprocessor კლასში, სადაც preprocessing ეტაპზე უკვე მოხდა არასაჭირო ან ნაკლებად რელევანტური ფიჩერების მოცილება.

---

# Training  
### ტესტირებული მოდელები  
- **Linear Regression (Baseline)** — მარტივი pipeline, მაღალი ვარიაციით  
- **Ridge Regression** — რეგულარიზაციის დამატება, სტაბილურობის გაუმჯობესება 
- **Random Forest (Final Model)** — მრავალ decision tree-ზე დაფუძნებული მოდელი, რომელმაც საუკეთესო ბალანსი აჩვენა bias/variance შორის

#### Linear Regression Baseline  
- მაღალი ვარიაცია და overfitting, განსაკუთრებით მცირე მონაცემებზე  
- Train RMSE: ~19,000 | Test RMSE: ~29,000

#### Ridge Regression
- უფრო მეტად გენერალიზაცია გააკეთა ამ მოდელმა, ნაკლები ოვერფიტი ჰქონდა, ტრაინზე მიღებული შედეგით ოდნავ მაღალი ერორი ჰქონდა ტესტზე
- Train RMSE: 29889.8 | MAE: 18839.8 | R²: 0.85
- Test  RMSE: 33224.5 | MAE: 20727.9 | R²: 0.856

- აქ ასევე ვცადე უფრო მეტი ფიჩერის ამოღება ხელით რომელიც ჩემი აზრით ნაკლებ გავლენას მოახდენდა ფასის დაპრედიქტებაში და თითქმის იდენტური შედეგი დადო მოდელმა, რმსემ კი აიწია მაგრამ აბსოლუტ სხვაობამ დაიწია ეს ყოველივე ძალიან ოდნავი ცვლილებებია და თითქმის იდენტური.
- Train RMSE: 30319.8 | MAE: 18949.1 | R²: 0.846
- Test  RMSE: 34302.6 | MAE: 20357.7 | R²: 0.847

#### Random Forest
- ამ მოდელის დროსაც გამოვიყენე ყველაფერი ზემოთ ხსენებული პრეპროცესინგი, ხელითაც ამოვიღე უმნიშვნელო ფიჩერები, ასევე გამოვიყენე WOE და One hot encoding, MissingValueHandler და კორელაციის ფილტრები. ამ მოდელმა საუკეთესოდ დაისწავლა სატრენინგო დატა, მაგრამ ტესტზე ეგეთი კარგი შედეგი ვერ აჩვენა,ასევე ძალიან მაღალი R² ტრეინზე რაც ოვერფიტის მაჩვენებელია , ასევე ვარიაციაც შედარებით მაღალი გვაქვს. მაგრამ საბოლოო მეტრიკებზე დაყრდნობით გადავწყვიტე საბოლოო მოდელად ეს ამერჩია.
- Train RMSE: 11948.4 | MAE: 7983.9 | R²: 0.976
- Test  RMSE: 27938.9 | MAE: 16910.6 | R²: 0.898
---

# Hyperparameter ოპტიმიზაციის მიდგომა  
- გამოყენებულია **GridSearchCV**, k-fold cross-validation-ით, 5 fold  
- სხვადასხვა ჰიპერპარამეტრების კომბინაცია Random Forest-ისთვის  

    'model__max_depth': [3, 5, 10, None],
    'model__n_estimators': [100, 200],
    'model__min_samples_split': [2, 5, 10],
    'model__min_samples_leaf': [1, 2],

- შეფასება ხდება RMSE და MAE მიხედვით

### საბოლოო მოდელის შერჩევის დასაბუთება  
Random Forest-მ მოიპოვა საუკეთესო შედეგები სხვა მოდელებთან შედარებით. მიუხედავად იმისა, რომ ტრეინზე დაბალი ერორები ჰქონდა, ტესტზეც შედარებით დაბალი დარჩა და საუკეთესო R² აჩვენა სხვა მოდელებთან შედარებით. მგონია რომ მიუხედავად იმისა რომ Ridge ნაკლები ვარიაციით გამოირჩევა და ნაკლები ოვერფიტი გვაქვს , მეტრიკები მაინც არ არის სასურველი ჩემთვის და Random Forest მეტად დაბალ ერორს აჩვენებს მაღალი R² შესაბამისად ეს მოდელი ავარჩიე საბოლოო მოდელად.

---

# MLflow Tracking  
### MLflow ექსპერიმენტების ბმული  
> [https://dagshub.com/losaberidzebadri/House-Prices-Regression.mlflow](#)

### ჩაწერილი მეტრიკების აღწერა  
- RMSE, MAE, R² როგორც ტრენინგზე, ასევე ტესტზე  

### საუკეთესო მოდელის შედეგები  
**Random Forest:**  
- **Train RMSE**: 11,948.39  
- **Train MAE**: 7,983.87  
- **Train R²**: 0.9761  
- **Test RMSE**: 27,938.90  
- **Test MAE**: 16,910.62  
- **Test R²**: 0.8982

### Kaggle კონკურსის ლინკი 
> [https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/overview](#)
